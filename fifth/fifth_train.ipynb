{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "from PIL import Image\n",
    "\n",
    "from keras.preprocessing import image\n",
    "from keras.layers import Input, Conv2D,  Dropout,Lambda, merge, Dense, Flatten,MaxPooling2D\n",
    "from keras.models import Model, Sequential\n",
    "from keras.regularizers import l2\n",
    "from keras import backend as K\n",
    "from keras.optimizers import SGD,Adam,Adadelta\n",
    "from keras.losses import binary_crossentropy\n",
    "import numpy.random as rng\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.utils import shuffle\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "path =\"/home/wei/data/fifth/train\"\n",
    "label = \"/home/wei/data/fifth/label.txt\"\n",
    "\n",
    "\n",
    "height = 45\n",
    "width = 45\n",
    "dirlist = []\n",
    "for root, dirs, files in os.walk(path):\n",
    "    for dir in dirs :\n",
    "        dirlist.append(dir)\n",
    "with open(label) as file_object:\n",
    "    p = file_object.readlines()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num = 0\n",
    "X1 = np.zeros((len(dirlist)*8,45,45,3), dtype = np.uint8)\n",
    "X2 = np.zeros((len(dirlist)*8,45,45,3), dtype = np.uint8)\n",
    "y = np.zeros((len(dirlist)*8, 1), dtype = np.uint8)\n",
    "\n",
    "for dir in dirlist:\n",
    "    images1 = []\n",
    "    images2 = []\n",
    "            \n",
    "    \n",
    "    image1 = Image.open(path+'/'+dir+'/'+dir+'.jpg')\n",
    "    image1 = image1.resize((180,45),)\n",
    "                    \n",
    "    for i in range(4):\n",
    "        left = 45*i\n",
    "        right = 45 * (i+1)\n",
    "        box = (left,0,right,45)\n",
    "        data = np.asarray(image1.crop(box))\n",
    "        images1.append(data)\n",
    "        \n",
    "    for l in p:\n",
    "        if l[:4] == dir:\n",
    "            break;\n",
    "    \n",
    "    \n",
    "    for i in range(4):\n",
    "        \n",
    "        im = np.asarray(Image.open(path+'/'+dir+'/'+l[5+i]+'.jpg'))\n",
    "        X1[num] = images1[i]\n",
    "        X2[num] = im\n",
    "        y[num] = 1\n",
    "        num += 1\n",
    "        im = np.asarray(Image.open(path+'/'+dir+'/'+str((int(l[5+i])+8)%9)+'.jpg'))                           \n",
    "        X1[num] = images1[i]\n",
    "        X2[num] = im\n",
    "        num += 1\n",
    "        \n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ok\n"
     ]
    }
   ],
   "source": [
    "#保存成pkl文件\n",
    "file = open('/home/wei/data/fifth/f_data/data8.pkl','wb')\n",
    "pickle.dump(([X1,X2],y) , file)\n",
    "print(\"ok\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/home/wei/data/fifth/vval/data1.pkl'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-66c5824cf7c5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#读取pickle文件\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mfile\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/home/wei/data/fifth/vval/data1.pkl'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mX1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mX2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"ok\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/home/wei/data/fifth/vval/data1.pkl'"
     ]
    }
   ],
   "source": [
    "#读取pickle文件\n",
    "file = open('/home/wei/data/fifth/f_data/data8.pkl', 'rb')\n",
    "[X1,X2], y = pickle.load(file)\n",
    "print(\"ok\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:29: UserWarning: Update your `Model` call to the Keras 2 API: `Model(outputs=Tensor(\"de..., inputs=[<tf.Tenso...)`\n"
     ]
    }
   ],
   "source": [
    "input_shape = (45, 45, 3)    \n",
    "left_input = Input(input_shape)\n",
    "right_input = Input(input_shape)\n",
    "convnet = Sequential()\n",
    "\n",
    "convnet.add(Conv2D(32,(7,7),padding='same',activation='relu',input_shape=input_shape ))\n",
    "convnet.add(Conv2D(32,(5,5),padding='same',activation='relu'))\n",
    "convnet.add(MaxPooling2D())\n",
    "\n",
    "convnet.add(Conv2D(64,(5,5),padding='same',activation='relu'))\n",
    "convnet.add(Conv2D(64,(3,3),padding='same',activation='relu'))\n",
    "convnet.add(MaxPooling2D())\n",
    "\n",
    "convnet.add(Conv2D(128,(3,3),padding='same',activation='relu'))\n",
    "convnet.add(Conv2D(256,(3,3),padding='same',activation='relu'))\n",
    "convnet.add(MaxPooling2D())\n",
    "\n",
    "convnet.add(Flatten())\n",
    "convnet.add(Dropout(0.35))\n",
    "convnet.add(Dense(2048,activation=\"relu\"))\n",
    "                  \n",
    "encoded_l = convnet(left_input)\n",
    "encoded_r = convnet(right_input)\n",
    "\n",
    "L1_layer = Lambda(lambda tensors:K.abs(tensors[0] - tensors[1]))        \n",
    "\n",
    "L1_distance = L1_layer([encoded_l, encoded_r])\n",
    "prediction = Dense(1,activation='sigmoid')(L1_distance)  \n",
    "model = Model(input = [left_input,right_input],outputs=prediction)\n",
    "\n",
    "\n",
    "optimizer = Adadelta(lr=0.1)\n",
    "\n",
    "model.compile(loss=\"binary_crossentropy\",optimizer=optimizer,metrics = ['accuracy'])  \n",
    "\n",
    "checkpointer = ModelCheckpoint(filepath=\"/home/wei/weight_5.3/weights.{epoch:02d}--{val_loss:.2f}-{val_acc:.4f}.hdf5\", \n",
    "                               verbose=2, save_weights_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 69840 samples, validate on 7760 samples\n",
      "Epoch 1/2\n",
      "69824/69840 [============================>.] - ETA: 0s - loss: 0.0419 - acc: 0.9873\n",
      "Epoch 00001: saving model to /home/wei/weight_5.3/weights.01--0.11-0.9589.hdf5\n",
      "69840/69840 [==============================] - 3956s 57ms/step - loss: 0.0419 - acc: 0.9873 - val_loss: 0.1103 - val_acc: 0.9589\n",
      "Epoch 2/2\n",
      "69824/69840 [============================>.] - ETA: 0s - loss: 0.0289 - acc: 0.9906\n",
      "Epoch 00002: saving model to /home/wei/weight_5.3/weights.02--0.15-0.9465.hdf5\n",
      "69840/69840 [==============================] - 3904s 56ms/step - loss: 0.0289 - acc: 0.9906 - val_loss: 0.1481 - val_acc: 0.9465\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f4a387484a8>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit([X1,X2], y,epochs=2,callbacks=[checkpointer],validation_split=0.1)\n",
    "\n",
    "\n",
    "# file = open('/home/wei/data/fifth/f_data/data5.pkl', 'rb')\n",
    "# [X1,X2], y = pickle.load(file)\n",
    "# model.fit([X1,X2], y,epochs=2,callbacks=[checkpointer],validation_split=0.1)\n",
    "\n",
    "\n",
    "# file = open('/home/wei/data/fifth/f_data/data4.pkl', 'rb')\n",
    "# [X1,X2], y = pickle.load(file)\n",
    "# model.fit([X1,X2], y,epochs=2,callbacks=[checkpointer],validation_split=0.1)\n",
    "\n",
    "# file = open('/home/wei/data/fifth/f_data/data3.pkl', 'rb')\n",
    "# [X1,X2], y = pickle.load(file)\n",
    "# model.fit([X1,X2], y,epochs=2,callbacks=[checkpointer],validation_split=0.1)\n",
    "\n",
    "# file = open('/home/wei/data/fifth/f_data/data2.pkl', 'rb')\n",
    "# [X1,X2], y = pickle.load(file)\n",
    "# model.fit([X1,X2], y,epochs=2,callbacks=[checkpointer],validation_split=0.1)\n",
    "\n",
    "\n",
    "# file = open('/home/wei/data/fifth/f_data/data1.pkl', 'rb')\n",
    "# [X1,X2], y = pickle.load(file)\n",
    "# model.fit([X1,X2], y,epochs=2,callbacks=[checkpointer],validation_split=0.1)\n",
    "\n",
    "\n",
    "# # file = open('/home/wei/data/fifth/f_data/data4.pkl', 'rb')\n",
    "# # [X1,X2], y = pickle.load(file)\n",
    "# # model.fit([X1,X2], y,epochs=2,callbacks=[checkpointer],validation_split=0.1)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.save_weights('/home/wei/data/fifth/data_model_weights.h5')\n",
    "model.save('/home/wei/data/fifth/data_model.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
